# ═══════════════════════════════════════════════════════════════════════════════
# M.I.A - Multimodal Intelligent Assistant
# Configuration File (Auto-Detection Enabled)
# ═══════════════════════════════════════════════════════════════════════════════
# Este arquivo contém configurações padrão. O M.I.A detecta automaticamente
# modelos locais disponíveis e permite seleção interativa ao iniciar.
# NÃO é necessário modificar este arquivo para uso básico.
# ═══════════════════════════════════════════════════════════════════════════════

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ LLM Configuration - Auto-detected at startup                                │
# └─────────────────────────────────────────────────────────────────────────────┘
# O M.I.A detecta automaticamente modelos Ollama instalados e APIs configuradas.
# Na inicialização, você pode escolher entre modelo local ou API externa.
#
# API Keys são configuradas via variáveis de ambiente:
# - OPENAI_API_KEY
# - ANTHROPIC_API_KEY  
# - GOOGLE_API_KEY (Gemini)
# - GROQ_API_KEY
# - XAI_API_KEY (Grok)

llm:
  selection_mode: interactive   # auto | interactive
  provider: auto                # auto-detectado na inicialização
  model_id: null                # auto-detectado
  api_key: null                 # via variável de ambiente
  url: null                     # auto-detectado
  max_tokens: 2048
  temperature: 0.7
  timeout: 60
  stream: true
  local:
    enabled: true
    model_path: null
    device: auto
    quantization: null
    max_memory: null
  ollama:
    url: http://localhost:11434
    auto_detect: true

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ Audio Configuration                                                          │
# └─────────────────────────────────────────────────────────────────────────────┘
audio:
  enabled: true
  sample_rate: 16000
  chunk_size: 1024
  device_id: null
  input_threshold: 0.01
  speech_model: openai/whisper-base.en
  
  # Text-to-Speech
  tts_enabled: true
  tts_provider: local           # local | piper | coqui | pyttsx3 | openai | custom
  tts_model_id: null
  tts_api_key: null
  tts_url: null
  
  # Voice Activity Detection
  vad_enabled: false
  vad_aggressiveness: 2
  vad_frame_duration_ms: 30
  vad_silence_duration_ms: 600
  
  # Playback
  playback_enabled: true
  push_to_talk: false
  
  # Hotword
  hotword_enabled: true
  hotword: mia
  hotword_sensitivity: 0.5
  hotword_timeout: 20.0

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ Embedding Configuration                                                      │
# └─────────────────────────────────────────────────────────────────────────────┘
# Embedding models para semantic search, RAG, clustering, e fine-tuning.
# Provedores: sentence-transformers (local), openai, ollama, cohere, voyageai

embedding:
  enabled: true
  provider: auto                # auto | sentence-transformers | openai | ollama | cohere | voyageai
  model_id: null                # auto-detectado (ex: all-MiniLM-L6-v2, text-embedding-3-small)
  api_key: null                 # via variável de ambiente
  url: null                     # para providers customizados
  dimension: 768                # dimensão do embedding (auto-ajustado pelo modelo)
  batch_size: 32                # tamanho do batch para processamento
  normalize: true               # normalizar embeddings (cosine similarity)
  cache_enabled: true           # cache de embeddings computados
  device: auto                  # auto | cpu | cuda | mps
  max_length: 512               # comprimento máximo do texto
  pooling_strategy: mean        # mean | cls | max

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ OCR Configuration                                                            │
# └─────────────────────────────────────────────────────────────────────────────┘
# OCR para extração de texto de imagens com integração LLM.
# Provedores locais: tesseract, easyocr, paddleocr, trocr
# Provedores cloud: openai (GPT-4V), anthropic (Claude Vision), google, azure

ocr:
  enabled: true
  provider: auto                # auto | tesseract | easyocr | paddleocr | trocr | openai | anthropic
  languages:                    # idiomas para reconhecimento
    - en
    - pt
  model_id: null                # modelo específico (ex: microsoft/trocr-base-printed)
  api_key: null                 # via variável de ambiente para cloud providers
  device: auto                  # auto | cpu | cuda
  confidence_threshold: 0.5     # confiança mínima para texto reconhecido
  preprocessing: true           # pré-processar imagem antes do OCR
  deskew: true                  # corrigir inclinação da imagem
  denoise: true                 # remover ruído
  binarize: false               # converter para preto e branco
  enhance_contrast: true        # melhorar contraste
  detect_orientation: true      # detectar orientação do texto
  llm_enhanced: true            # usar LLM para extração estruturada

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ Vision Configuration                                                         │
# └─────────────────────────────────────────────────────────────────────────────┘
vision:
  enabled: true
  model: openai/clip-vit-base-patch32
  device: auto
  max_image_size: 1024
  supported_formats:
    - jpg
    - jpeg
    - png
    - bmp
    - gif
    - webp

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ Memory Configuration                                                         │
# └─────────────────────────────────────────────────────────────────────────────┘
memory:
  enabled: true
  vector_enabled: true
  graph_enabled: true
  long_term_enabled: true
  vector_db_path: memory/
  max_memory_size: 10000
  embedding_dimension: 768
  similarity_threshold: 0.7
  max_results: 5

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ Security Configuration                                                       │
# └─────────────────────────────────────────────────────────────────────────────┘
security:
  enabled: true
  max_file_size: 10485760
  allowed_file_types:
    - txt
    - md
    - py
    - json
    - yaml
    - js
    - ts
    - html
    - css
  blocked_commands:
    - rm -rf
    - del /f
    - format
    - fdisk
  max_command_length: 1000
  audit_logging: true

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ System Configuration                                                         │
# └─────────────────────────────────────────────────────────────────────────────┘
system:
  debug: false
  log_level: INFO
  max_workers: 4
  request_timeout: 60
  retry_attempts: 3
  cache_enabled: true
  cache_ttl: 3600
  language: pt-BR               # Idioma padrão: pt-BR | en-US

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ Sandbox Configuration                                                        │
# └─────────────────────────────────────────────────────────────────────────────┘
sandbox:
  enabled: true
  work_dir: sandbox_runs
  log_dir: logs/sandbox
  runtime: auto
  max_memory_mb: 256
  timeout_ms: 10000
  fuel: null

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ Documents Configuration                                                      │
# └─────────────────────────────────────────────────────────────────────────────┘
documents:
  template_dir: templates/documents
  output_dir: output/documents
  default_template: proposal

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ Telegram Configuration                                                       │
# └─────────────────────────────────────────────────────────────────────────────┘
telegram:
  enabled: false
  api_id: null
  api_hash: null
  bot_token: null
  phone_number: null
  session_dir: sessions
  session_name: mia_telegram
  default_peer: null
  parse_mode: markdown
  request_timeout: 30

# ┌─────────────────────────────────────────────────────────────────────────────┐
# │ MCP Configuration                                                           │
# └─────────────────────────────────────────────────────────────────────────────┘
mcp_servers:
  # Example configuration for a filesystem server
  # filesystem:
  #   command: "npx"
  #   args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
  #   enabled: false
